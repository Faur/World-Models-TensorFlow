{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS DEPRICATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_old = False # model\n",
    "use_old_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Lambda, Conv2D, Flatten, Conv2DTranspose, Reshape, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "from keras.activations import softmax\n",
    "from keras.objectives import binary_crossentropy as bce\n",
    "from keras.objectives import mean_squared_error as mse\n",
    "\n",
    "%pylab inline\n",
    "import os\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, \"/media/toke/Armory/tank/git/World-Models-TensorFlow/stateless_agent\")\n",
    "from train_Gumbel_VAE import Network, show_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "\n",
    "if use_old_data:\n",
    "    data1 = \"small_obs_data_car_racing_1.npy\"\n",
    "\n",
    "    np_dat = np.load(os.path.join(data_dir, data1))\n",
    "    x_train = np_dat[:8000]\n",
    "    x_test = np_dat[8000:]\n",
    "    print(x_train.shape, x_test.shape)\n",
    "    print(np.min(x_train), np.max(x_train))\n",
    "    print(x_train.dtype)\n",
    "\n",
    "    plt.imshow(x_train[70])\n",
    "else:\n",
    "\n",
    "    data1 = \"obs_data_VAE_0.npy\"\n",
    "    print(data1)\n",
    "    np_dat = np.load(os.path.join(data_dir, data1))\n",
    "\n",
    "    data1 = \"obs_data_VAE_1.npy\"\n",
    "    print(data1)\n",
    "    data = np.load(os.path.join(data_dir, data1))\n",
    "    np_dat = np.concatenate([np_dat, data])\n",
    "\n",
    "    data1 = \"obs_data_VAE_2.npy\"\n",
    "    print(data1)\n",
    "    data = np.load(os.path.join(data_dir, data1))\n",
    "    np_dat = np.concatenate([np_dat, data])\n",
    "\n",
    "    data1 = \"obs_data_VAE_3.npy\"\n",
    "    print(data1)\n",
    "    data = np.load(os.path.join(data_dir, data1))\n",
    "    np_dat = np.concatenate([np_dat, data])\n",
    "\n",
    "\n",
    "    np_dat = resize(np_dat, (len(np_dat), 64, 64, 3), anti_aliasing=True).astype(np.float32)\n",
    "    x_train = np_dat[:8000]\n",
    "    x_test = np_dat[8000:]\n",
    "    print(x_train.shape, x_test.shape)\n",
    "    print(np.min(x_train), np.max(x_train))\n",
    "    print(x_train.dtype)\n",
    "\n",
    "    plt.imshow(x_train[89])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling(logits_y):\n",
    "    U = K.random_uniform(K.shape(logits_y), 0, 1)\n",
    "    y = logits_y - K.log(-K.log(U + 1e-20) + 1e-20) # logits + gumbel noise\n",
    "    y = softmax(K.reshape(y, (-1, N, M)) / tau)\n",
    "#     y = softmax(K.reshape(y, (N, M)) / tau,axis=-1)\n",
    "    y = K.reshape(y, (-1, N*M))\n",
    "    return y\n",
    "\n",
    "\n",
    "# def gumbel_loss(x, x_hat):\n",
    "#     q_y = K.reshape(logits_y, (-1, N, M))\n",
    "#     q_y = softmax(q_y)\n",
    "#     log_q_y = K.log(q_y + 1e-20)\n",
    "#     kl_tmp = q_y * (log_q_y - K.log(1.0/M))\n",
    "#     KL = K.sum(kl_tmp, axis=(1, 2))\n",
    "# #     elbo = data_dim * bce(x, x_hat) - KL \n",
    "#     elbo = DATA_DIM * bce(x, x_hat) - KL\n",
    "#     return elbo\n",
    "\n",
    "# def gumbel_loss(x, x_hat):\n",
    "#     print(K.shape(logits_y))\n",
    "#     q_y = K.reshape(logits_y, (-1, N, M))\n",
    "#     print(K.shape(logits_y))\n",
    "#     q_y = softmax(q_y)\n",
    "#     log_q_y = K.log(q_y + 1e-20)\n",
    "#     kl_tmp = q_y * (log_q_y - K.log(1.0/M))\n",
    "#     KL = K.sum(kl_tmp, axis=(1, 2))\n",
    "# #     elbo = data_dim * bce(x, x_hat) - KL \n",
    "#     elbo = DATA_DIM * bce(x, x_hat) - KL\n",
    "#     return elbo\n",
    "\n",
    "def gumbel_loss(x, x_hat):\n",
    "    q_y = K.reshape(logits_y, (-1, N, M))\n",
    "    q_y = softmax(q_y)\n",
    "    log_q_y = K.log(q_y + 1e-20)\n",
    "    kl_tmp = q_y * (log_q_y - K.log(1.0/M))\n",
    "    KL = K.sum(kl_tmp, axis=(1, 2))\n",
    "    x = K.reshape(x, (1,-1))\n",
    "    x_hat = K.reshape(x_hat, (1,-1))\n",
    "#     elbo = DATA_DIM * bce(x, x_hat) - KL\n",
    "    elbo = DATA_DIM * mse(x, x_hat) - KL\n",
    "    return elbo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots():\n",
    "    argmax_y = K.max(K.reshape(logits_y, (-1, N, M)), axis=-1, keepdims=True)\n",
    "    argmax_y = K.equal(K.reshape(logits_y, (-1, N, M)), argmax_y)\n",
    "    # encoder = K.function([x], [argmax_y, x_hat])\n",
    "    encoder = K.function([x], [argmax_y, decoded_x])\n",
    "\n",
    "    # test_idx, try: from 160-180\n",
    "    test_idx = np.random.randint(len(x_test))\n",
    "    _batch = len(x_test)\n",
    "    code, x_hat_test = encoder([x_test[:_batch]])\n",
    "\n",
    "    _x_hat, _logits, _z = vae_test.predict(x_test[:_batch])\n",
    "\n",
    "    subplot(331)\n",
    "    title(\"Input image\")\n",
    "    # imshow(x_test[test_idx].reshape(28, 28), cmap='gray'), axis('off')\n",
    "    imshow(x_test[test_idx].reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "    subplot(334)\n",
    "    title(\"true\")\n",
    "    imshow(_z[test_idx].reshape(N, M), cmap='gray'), axis('off')\n",
    "\n",
    "    subplot(335)\n",
    "    title(\"decoder\")\n",
    "    img_true = generator.predict(np.reshape(_z[test_idx], (1,-1)) )\n",
    "    # imshow(img_true.reshape(28, 28), cmap='gray'), axis('off')\n",
    "    imshow(img_true.reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "    subplot(336)\n",
    "    title(\"full network\")\n",
    "    # imshow(x_hat_test[test_idx].reshape(28, 28), cmap='gray'), axis('off')\n",
    "    imshow(x_hat_test[test_idx].reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "\n",
    "    # imshow(x_hat_test[test_idx].reshape(28, 28), cmap='gray'), axis('off')\n",
    "    # imshow(x_hat_test[test_idx].reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "    subplot(337)\n",
    "    title(\"binary\")\n",
    "    imshow(code[test_idx].reshape(N, M), cmap='gray'), axis('off')\n",
    "\n",
    "    subplot(338)\n",
    "    title(\"binary x_hat\")\n",
    "    img_binary = generator.predict(np.reshape(code[test_idx], (1,-1)) )\n",
    "    # imshow(img_binary.reshape(28, 28), cmap='gray'), axis('off')\n",
    "    imshow(x_hat_test[test_idx].reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "INPUT_DIM = (64,64,3)\n",
    "DATA_DIM = np.prod(INPUT_DIM) \n",
    "N = 32  # Number var\n",
    "M = 8  #  Number values per var\n",
    "nb_epoch = 500 #100\n",
    "\n",
    "#tau = K.variable(5.0, name=\"temperature\")\n",
    "anneal_rate = np.log(2)/20\n",
    "print(anneal_rate)\n",
    "min_temperature = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tau = K.variable(5.0, name=\"temperature\")\n",
    "\n",
    "if use_old:\n",
    "    ACTIV = \"relu\"\n",
    "\n",
    "    # x = Input(batch_shape=(batch_size, data_dim ))\n",
    "    x = Input(shape=INPUT_DIM)\n",
    "    # h = Dense(256, activation='relu')(Dense(512, activation='relu')(x))\n",
    "    h = Conv2D(filters=32, kernel_size=4, strides=2, padding='same', activation=ACTIV)(x)\n",
    "    h = Conv2D(filters=64, kernel_size=4, strides=2, padding='same', activation=ACTIV)(h)\n",
    "    # h = Conv2D(filters=64, kernel_size=3, strides=2, padding='valid', activation=ACTIV)(h)\n",
    "    h = Flatten()(h)\n",
    "\n",
    "    logits_y = Dense(M*N, activation=None)(h)\n",
    "\n",
    "    # z = Lambda(sampling, output_shape=(M*N,))(logits_y)\n",
    "    z_lay = Lambda(sampling, output_shape=(M*N,))\n",
    "    z = z_lay(logits_y)\n",
    "    z = Activation(None)(z)\n",
    "\n",
    "    # z = Reshape((1,1,N*M))(z)\n",
    "    # z = Conv2DTranspose(filters=32, kernel_size=6, strides=4, padding=\"same\")(z)\n",
    "    # z = Conv2DTranspose(filters=32, kernel_size=3, strides=4, padding=\"same\")(z)\n",
    "    # z = Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding=\"same\")(z)\n",
    "    # x_hat = Conv2DTranspose(filters=3, kernel_size=3, strides=2, padding=\"same\")(z)\n",
    "\n",
    "    z_1 = Reshape((1,1,N*M))\n",
    "    z_2 = Conv2DTranspose(filters=32, kernel_size=4, strides=2, padding=\"same\", activation=ACTIV)\n",
    "    z_3 = Conv2DTranspose(filters=32, kernel_size=4, strides=2, padding=\"same\", activation=ACTIV)\n",
    "    z_4 = Conv2DTranspose(filters=16, kernel_size=4, strides=2, padding=\"same\", activation=ACTIV)\n",
    "    z_5 = Conv2DTranspose(filters=16, kernel_size=4, strides=4, padding=\"same\", activation=ACTIV)\n",
    "    x_hat = Conv2DTranspose(filters=3, kernel_size=4, strides=2, padding=\"same\", activation=\"sigmoid\")\n",
    "\n",
    "    decode_input = Input( shape=(M*N,) )\n",
    "    decoder = x_hat(z_5(z_4(z_3(z_2(z_1( decode_input ))))))\n",
    "    generator = Model(decode_input, decoder)\n",
    "    \n",
    "    decoded_x = x_hat(z_5(z_4(z_3(z_2(z_1( z ))))))\n",
    "    vae = Model(x, decoded_x)\n",
    "    vae.compile(optimizer='adam', loss=gumbel_loss)\n",
    "    vae.summary()\n",
    "\n",
    "    vae_test = Model(x, [decoded_x, logits_y, z])\n",
    "    \n",
    "else:\n",
    "    vae = Network(N,M)\n",
    "    vae.tau =  tau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for e in range(nb_epoch):\n",
    "    print(e, \"/\", nb_epoch, '- K:', K.get_value(tau))\n",
    "    if use_old:\n",
    "        K.set_value(tau, np.max([min_temperature, 5.0 * np.exp(- anneal_rate * e)]))\n",
    "        train_hist = vae.fit(x_train, x_train, \n",
    "        shuffle=True, \n",
    "        epochs=1, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))\n",
    "    else:\n",
    "        K.set_value(vae.tau, np.max([min_temperature, 5.0 * np.exp(- anneal_rate * e)]))\n",
    "        train_hist = vae.model.fit(x_train, x_train, \n",
    "            shuffle=True, \n",
    "            epochs=1, \n",
    "            batch_size=batch_size,\n",
    "            validation_data=(x_test, x_test))\n",
    "\n",
    "    if e % 2==0 or e == nb_epoch-1:\n",
    "        fig = plt.figure(1, figsize=(10,5))\n",
    "        if use_old:\n",
    "            make_plots()\n",
    "       \n",
    "        else:\n",
    "            print(\"Validation score\", vae.model.evaluate(x_test, x_test))\n",
    "\n",
    "            logits, gumbel, pred = vae.tester.predict(x_test)\n",
    "            n = np.random.randint(len(x_test))\n",
    "            subplot(221)\n",
    "            plt.imshow(x_test[n])\n",
    "            title = \"e{} n{}\".format(e,n)\n",
    "            subplot(222)\n",
    "            plt.imshow(pred[n])\n",
    "            plt.tight_layout()\n",
    "\n",
    "            subplot(223)\n",
    "            plt.imshow(np.reshape(gumbel[n], (N,M)).T)\n",
    "            # plt.colorbar()\n",
    "            subplot(224)\n",
    "            plt.imshow(np.reshape(logits[n], (N,M)).T)\n",
    "            plt.colorbar()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "#             show_pred(title, x_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# vae.save_weights('model3_vae_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_y = K.max(K.reshape(logits_y, (-1, N, M)), axis=-1, keepdims=True)\n",
    "argmax_y = K.equal(K.reshape(logits_y, (-1, N, M)), argmax_y)\n",
    "# encoder = K.function([x], [argmax_y, x_hat])\n",
    "encoder = K.function([x], [argmax_y, decoded_x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sample 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# N = 10\n",
    "# M = 5\n",
    "\n",
    "img_code = np.zeros( (N,M) )\n",
    "\n",
    "def f(*args,**kwargs):\n",
    "#     print(kwargs)\n",
    "    for i, key in enumerate(kwargs):\n",
    "#         print( kwargs[key] )\n",
    "        zero_row = np.zeros((1,M))\n",
    "        zero_row[0, kwargs[key] ] = 1\n",
    "        img_code[i] = zero_row\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img_code, cmap=\"gray\")\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    img_binary = generator.predict(np.reshape(img_code, (1,-1)) )\n",
    "#     plt.imshow(img_binary.reshape(28, 28), cmap='gray')\n",
    "    plt.imshow(img_binary.reshape(64, 64, 3), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "kw_dict = {}\n",
    "for n in range(N):\n",
    "    kw_dict[\"z\"+str(n)] = widgets.IntSlider(description=\"z\"+str(n), min=0, max=(M-1), value=int(M/2), continuous_update=False)\n",
    "\n",
    "interactive_plot = interactive(f, **kw_dict)\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '350px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sample 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.zeros( (N,M) )\n",
    "\n",
    "for i in range(N):\n",
    "    sample[i, np.random.randint(0,M)] = 1.0\n",
    "\n",
    "# print(sample)\n",
    "# imshow(sample, cmap='gray'), axis('off')\n",
    "imshow(code[test_idx].reshape(N, M), cmap='gray'), axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def softmaxx(x):\n",
    "#     \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def softmaxx(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    arr = []\n",
    "    for row in x:\n",
    "        e_x = np.exp(row - np.max(row))\n",
    "        e_x = e_x / e_x.sum()\n",
    "        arr.append(e_x)\n",
    "#         print(e_x)\n",
    "    return np.asarray(arr)\n",
    "\n",
    "\n",
    "def sampl(logits_y, tau):\n",
    "#     U = K.random_uniform(K.shape(logits_y), 0, 1)\n",
    "#     print(\"LOGITS_Y\")\n",
    "#     print(logits_y)\n",
    "    U = np.random.uniform(0, 1, logits_y.shape)\n",
    "#     print(\"U !!!\")\n",
    "#     print(U)\n",
    "    y = logits_y - np.log(-np.log(U + 1e-20) + 1e-20) # logits + gumbel noise\n",
    "#     print(\"y: logits minus gumbel\")\n",
    "#     print(y)\n",
    "    y = softmaxx(np.reshape(y, (-1, N, M)) / tau)\n",
    "#     print(\"y after softmax\")\n",
    "#     print(y)\n",
    "    y = np.reshape(y, (-1, N*M))\n",
    "#     print(\"y after reshape\")\n",
    "#     print(y)\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20): \n",
    "  \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "  U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "  return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature): \n",
    "  \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "  y = logits + sample_gumbel(tf.shape(logits))\n",
    "  return tf.nn.softmax( y / temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sampl( np.random.rand(M*N), 0.1 )\n",
    "# b = sampl( np.random.rand(M*N)*100, 0.1 )\n",
    "# c = sampl( np.zeros((1,M*N)), 0.1 )\n",
    "\n",
    "# b = np.reshape(b, (N,M))\n",
    "# b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code, x_hat_test = encoder([x_test[:1]])\n",
    "rand_code = np.eye(M)[np.random.choice(M, N)]\n",
    "rand_img = generator.predict(np.reshape(rand_code, [-1,N*M]))\n",
    "sampl_code = bli\n",
    "sampl_img =  generator.predict(np.reshape(sampl_code, [-1,N*M]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_reshaped = rand_img.reshape(28,28)\n",
    "img_reshaped = sampl_img.reshape(28,28)\n",
    "img_reshaped.shape\n",
    "plt.imshow(img_reshaped, cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
