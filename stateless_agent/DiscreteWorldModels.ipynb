{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "* video\n",
    "* put in all the data that is needed, except the large ones!\n",
    "\n",
    "#### DONE\n",
    "* logit vs log(softmax(logit))\n",
    "* Hard sampling for agent training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "**Deep learning approaches** (sub-symbolic) are capable processing high dimensional data like images much better than any previous technique.\n",
    "They do however have several drawbacks, a major of which is that models are very hard to analyze, making it difficult to know how the system will behave to a particular input, why a particular output was produced, or debug any issues that might arise.\n",
    "Traditional **logic based approaches** to artificial intelligence (symbolic) are bad at dealing natural data like images, but the internal mechanisms are much easier to understand.\n",
    "Logic based approaches also have advantages in some domains, for instance when long term planning is involved.\n",
    "\n",
    "Symbolic and sub-symbolic approaches are largely incompatible due to the lack of a coherent way to interface between them [4].\n",
    "Since the strengths and weaknesses of these fields compliment each other so well such an interface is of great practical and scientific importance.\n",
    "Asai and Fukunaga [4] showed that it was possible to combine a neural network model and a classical planning algorithm via the use of discrete representations.\n",
    "Using their approach they were able to solve some simple puzzle like challenges (8-puzzel, tower of Hanoi) that had been modified such that they required a computer vision system in order to understand the state of the environment.\n",
    "\n",
    "\n",
    "\n",
    "Ha and Schmidhuber [3] proposed a simple yet powerfull framework, 'World Models' that separates modelling the environemnt and selecting which action to take.\n",
    "This framework is very similar to the one proposed by Asai and Fukunaga [4].\n",
    "With the key differences being that everyting is continuous, and a linear agent was used instead of a planner.\n",
    "Ha and Schmidhuber [3] were able to show that the World Model framework is capable of training large networks, and solve complicated environments (OpenAI CarRacing, ViZDoom).\n",
    "The agent used is however a simple linear agent, and it is therefore severely limited.\n",
    "\n",
    "\n",
    "The contribution of Asai and Fukunaga [4] is an important first step towards combining symbolic and sub-symbolic approaches.\n",
    "The problems tackled are however very simple and how well the proposed methods scale to more difficult problems remains to be seen.\n",
    "In this notebook we take a small step towards extending the work of Asai and Fukunaga [4] to more complicated problems by combining it with ideas from and Ha and Schmidhuber [3].\n",
    "Specifically in this notebook we train a network to learn a discrete representation of the [OpenAI CarRacing](https://gym.openai.com/envs/CarRacing-v0/) environment, and train a simple linear agent to control the car using reinforcement learning.\n",
    "\n",
    "> ![](CarRacing.png)\n",
    "> In CarRacing the objective is to control (accelerate, turn, break) the red car, such that it drives along as much of the track as possible in a given amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Representations\n",
    "A recent yet popular method of creating discrete representations with neural networks is by using the *Gumbel-softmax reparametrization trick* [5, 6], which is what we will use in this notebook.\n",
    "The Gumbel-softmax reparametrization trick was already covered in the previous ontebook which will not be rehashed here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Models\n",
    "The World Models framework proposed by Ha and Schmidhuber [3] is an example of *model based reinforcement learning* i.e. a model of the enironment is learnt, which is then used to train the agent (in part or fully).\n",
    "This approach has many advantages[1, 2], for instance:\n",
    " * **Prior knowledge** of the environment can be encoded more easily than in model-free methods.\n",
    " * **Transfer learning** between tasks for the same environment is easily facilitated through models.\n",
    " * **High-dimentional observations** introduce several complexitites (curse of dimensionality) making it harder to solve a task. Models can typically provide low-dimensional representations that simplify the problem greatly.\n",
    " * **Data efficent learning:** Model based approaches are generally much more data effcient that model-free, which makes a big difference when data is expensive to obtain as it limits the interactions with the true environment, potenitally making training safer and faster when the environment is physical or requires complex computations.(e.g. robots).\n",
    " * **Internal Simulator** makes it possible to rollout several scenarios before making an action - enabling the use of methods like Monte Carlo tree search. This also helps with planning through by making long-term predictions through rollouts.\n",
    "\n",
    "\n",
    "The World Models framework consists of three components that work closely together: \n",
    "* **Vision (V):** A convolutional variational auto-encoder with a Gaussian latent space ($z$).\n",
    "* **Memory (M):** An auto-regressive model, implemented as an LSTM.\n",
    "* **Controller (C):** A simple linear controller.\n",
    "\n",
    "> ![Worldmodel diagram](images/worldmodel.png)\n",
    "> Figure 4 from [3]\n",
    "\n",
    "This setup with distinct modules enables V and M to be trained separately in a fully unsupervised way from data collected from a random policy.\n",
    "This training setup provides rich training signals, enabling the use of large networks for RL, something that typically isn't possible when using only the reward as it is a relatively weak training signal.\n",
    "Since C is just a linear model we can see that most of the environments complexity must reside in V and M.\n",
    "\n",
    "Ha and Schmidhuber [3] also show that it possible to train the agent entirely within hallucinated environments (V and M, rather than the actual environment) and transfer the learnt policy directly to the real environment.\n",
    "\n",
    "The 'World Models' framework that Ha and Schmidhuber [3] proposes combines several deep learning and reinforcement learning techniques into a simple architecture that achieve very good results.\n",
    "Further more it is possible to train the V and M models in less than an hour on a normal GPU, speeding up development and total training time significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook\n",
    "\n",
    "The remainder of this notebook will cover \n",
    "\n",
    "For the purposes of this project we will \n",
    "\n",
    "We will now demonstrate the code that\n",
    "1. implements both a continuous and a discrete variational auto-encoder, in order to compare our implementation with the continuous standard.\n",
    "1. \n",
    "\n",
    "extending the work of Asai and Fukunaga [4] to more complicated problems by combining it with ideas from and Ha and Schmidhuber [3]. Specifically in this notebook we train a network to learn a discrete representation of the OpenAI CarRacing environment,\n",
    "\n",
    "\n",
    "Compare continuous VAE and discrete VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the auto-encoders\n",
    "In the code snippets below we will \n",
    "1. generate training data for the VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training data for the VAE\n",
    "\n",
    "generate_vae_training_data = True\n",
    "generate_vae_training_data = False\n",
    "\n",
    "if generate_vae_training_data:\n",
    "    import generate_VAE_data\n",
    "    generate_VAE_data.main()\n",
    "else:\n",
    "    print('Pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training / loading the VAEs\n",
    "\n",
    "train_from_scratch = True\n",
    "train_from_scratch = False\n",
    "\n",
    "if train_from_scratch:\n",
    "    train_from_scratch = False # These commands cannot be run more than once per instance.\n",
    "    \n",
    "#     # Train continuous version\n",
    "#     print('Training continuous VAE')\n",
    "#     import train_VAE\n",
    "#     train_VAE.train_vae()\n",
    "    \n",
    "    print('Training discrete VAE')\n",
    "    import train_Gumbel_VAE\n",
    "    train_Gumbel_VAE.train_vae()\n",
    "else: # Load excisting weights\n",
    "    print('Pass')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in order to compare -- generate a random sequence - visualize latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent space visualization\n",
    "import train_Gumbel_VAE\n",
    "import train_VAE \n",
    "\n",
    "import visualize_VAE\n",
    "\n",
    "print('Generating data')\n",
    "data96, data64 = visualize_VAE.generate_data()\n",
    "max_len = data64.shape[0]\n",
    "\n",
    "print(\"Generating Discrete predictions\")\n",
    "sess_G, model_G = train_Gumbel_VAE.load_vae()\n",
    "pred_G = model_G.model.predict(data64, verbose=0)\n",
    "logits, pre_gumbel_softmax, gumbel, hard_sample = model_G.encoder([data64])\n",
    "\n",
    "print(\"Generating Continuous predictions\")\n",
    "sess_C, model_C = train_VAE.load_vae()\n",
    "pred_C, z = model_C.predict(sess_C, data96)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Continuous\n",
    "for n in range(max_len):\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(data[n])\n",
    "    plt.title('data '+str(n))\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(np.reshape(z[n], [4,8]), vmin=-5, vmax=5)\n",
    "    plt.title('z')\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(pred[n])\n",
    "    plt.title('pred - Continuous')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Discrete\n",
    "base_title = 'Gumbel'\n",
    "\n",
    "for n in range(max_len):\n",
    "    title = base_title+'-'+str(n) + ' - {}/{}'.format(n, max_len)\n",
    "\n",
    "    model_G.make_image(fig, title + ' i' + str(n), data64[n], logits[n],\n",
    "                    pre_gumbel_softmax[n],\n",
    "                    gumbel[n], hard_sample[n], pred_G[n])\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agent\n",
    "> * number of parameters\n",
    "> * Simplifications / cheats vs Worldmodels paper\n",
    "> * Loading vs training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training / loading the Agent\n",
    "\n",
    "train_agent_from_scratch = True\n",
    "train_agent_from_scratch = False\n",
    "\n",
    "if train_agent_from_scratch:\n",
    "    import train_agents\n",
    "    train_agents.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Video CAE vs DAE\n",
    "> * Agent learning cureve comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "During training the agent trained on the discrete distribution had many situations where the agent would stop, and due to low stochasticity in the system the agent would stay there for the remainder of the episode.\n",
    "Makes sense as the latent space is much smaller (in terms of bits)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aknowledgements\n",
    "https://medium.com/applied-data-science/how-to-build-your-own-world-model-using-python-and-keras-64fb388ba459\n",
    "\n",
    "https://github.com/dariocazzani/World-Models-TensorFlow\n",
    "\n",
    "https://github.com/AppliedDataSciencePartners/WorldModels\n",
    "\n",
    "https://github.com/hardmaru/WorldModelsExperiments\n",
    "\n",
    "\n",
    "# Refrences\n",
    "[1] Shakir Mohamed (2018) A Case Against Generative Models in RL?. Lecture at DALI 2018 Workshop on Generative Models in Reinforcement Learning. https://www.youtube.com/watch?v=EA2RtXsLSWU\n",
    "\n",
    "[2] Chelsea Finn (2017) Deep RL Bootcamp Lecture 9 Model-based Reinforcement Learning. Lecture at Deep RL Bootcamp. https://www.youtube.com/watch?v=iC2a7M9voYU&feature=youtu.be\n",
    "\n",
    "[3] Ha and Schmidhuber, \"World Models\", 2018. https://doi.org/10.5281/zenodo.1207631 https://worldmodels.github.io\n",
    "\n",
    "[4] Asai, M., & Fukunaga, A. (2017). Classical Planning in Deep Latent Space: Bridging the Subsymbolic-Symbolic Boundary. Retrieved from http://arxiv.org/abs/1705.00154, \n",
    "\n",
    "[5] Chris J. Maddison, Andriy Mnih, and Yee Whye Teh. “The Concrete Distribution: a Continuous Relaxation of Discrete Random Variables.” ICLR Submission, 2017.\n",
    "\n",
    "[6] Eric Jang, Shixiang Gu and Ben Poole. “Categorical Reparameterization by Gumbel-Softmax.” ICLR Submission, 2017."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
